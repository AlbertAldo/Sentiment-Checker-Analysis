{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize # (sent => sentence, word => word)\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems\n",
    "***In times like today, the development of social media is very rapidly and had an impact on an existing business. When word of mouth is carried out by netizens on a business product, it will have a good impact and a bad impact. If the good impact is received, it will make profits for the business company, but if the bad impact is carried out by certain individuals such as for example hate speech on the product, badmouthing the product, insulting the product it will harmful the business company,  Therefore it is necessary to have a machine that can assist in filtering negative sentiments that entering our business products.***\n",
    "\n",
    "## Goals\n",
    "***Can provide a solution to the problem above by making a machine that can predict a sentence that has a negative or positive connotation, to prevent negative sentences from entering our product business.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source\n",
    "    Thanks to all the sources who have given permission to use the data by publishing it on the website.\n",
    "    \n",
    "    The Source all as follows:\n",
    "    1. https://repo.telematika.org/project/louisowen6_nlp_bahasa_resources/\n",
    "    2. https://www.kaggle.com/ilhamfp31/indonesian-abusive-and-hate-speech-twitter-text?select=data.csv\n",
    "    3. https://rizalespe.github.io/Dataset-Sentimen-Analisis-Bahasa-Indonesia/\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Information\n",
    "1. The datasets are combined all from the above source, and it is an Indonesian Text.\n",
    "2. They are labeled into 1 (Positive Sentiment) and -1 (Negative Sentiment).\n",
    "3. Assisted with another source such as StopWords Indonesian from nltk, Emoticon and Slang Words from repo.telematika.org.\n",
    "4. This dataset including from Tweets, Instagram Comment, Single Word of Positive and Negative Sentiment Dictionary from repo.telematika.org.\n",
    "5. Using Sastrawi Package for stemming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning & Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file from txt type to csv type\n",
    "read_file1 = pd.read_csv('negatif_ta.txt')\n",
    "read_file1.to_csv('negatif_ta.csv', index=None)\n",
    "\n",
    "read_file2 = pd.read_csv('negatif_ta2.txt', delimiter='/')\n",
    "read_file2.to_csv('negatif_ta2.csv', index=None)\n",
    "\n",
    "read_file3 = pd.read_csv('negative_add.txt')\n",
    "read_file3.to_csv('negative_add.csv', index=None)\n",
    "\n",
    "read_file4 = pd.read_csv('negative_keyword.txt', delimiter='/')\n",
    "read_file4.to_csv('negative_keyword.csv', index=None)\n",
    "\n",
    "read_file5 = pd.read_csv('positif_ta.txt')\n",
    "read_file5.to_csv('positif_ta.csv', index=None)\n",
    "\n",
    "read_file6 = pd.read_csv('positif_ta2.txt')\n",
    "read_file6.to_csv('positif_ta2.csv', index=None)\n",
    "\n",
    "read_file7 = pd.read_csv('positive_add.txt')\n",
    "read_file7.to_csv('positive_add.csv', index=None)\n",
    "\n",
    "read_file8 = pd.read_csv('positive_keyword.txt')\n",
    "read_file8.to_csv('positive_keyword.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move csv type into a dataframe\n",
    "df_1 = pd.read_csv('negatif_ta.csv')\n",
    "df_2 = pd.read_csv('negatif_ta2.csv')\n",
    "df_3 = pd.read_csv('negative_add.csv')\n",
    "df_4 = pd.read_csv('negative_keyword.csv')\n",
    "\n",
    "df_5 = pd.read_csv('positif_ta.csv')\n",
    "df_6 = pd.read_csv('positif_ta2.csv')\n",
    "df_7 = pd.read_csv('positive_add.csv')\n",
    "df_8 = pd.read_csv('positive_keyword.csv')\n",
    "\n",
    "df_9 = pd.read_csv('abusive.csv')\n",
    "df_10 = pd.read_csv('data.csv', encoding='latin-1')\n",
    "df_11 = pd.read_csv('dataset_tweet_sentiment_cellular_service_provider.csv', encoding='utf-8')\n",
    "df_12 = pd.read_csv('master_emoji.csv', encoding='utf-8')\n",
    "df_13 = pd.read_csv('dataset_komentar_instagram_cyberbullying.csv', encoding='utf-8')\n",
    "df_14 = pd.read_csv('dataset_tweet_sentimen_tayangan_tv.csv', encoding='utf-8')\n",
    "df_15 = pd.read_csv('dataset_tweet_sentiment_opini_film.csv', encoding='utf-8')\n",
    "df_16 = pd.read_csv('dataset_tweet_sentiment_pilkada_DKI_2017.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-indexing dataframe\n",
    "df_1 = df_1.T.reset_index().T.reset_index().drop(columns='index')\n",
    "df_2 = df_2.T.reset_index().T.reset_index().drop(columns='index')\n",
    "df_3 = df_3.T.reset_index().T.reset_index().drop(columns='index')\n",
    "df_4 = df_4.T.reset_index().T.reset_index().drop(columns='index')\n",
    "\n",
    "df_5 = df_5.T.reset_index().T.reset_index().drop(columns='index')\n",
    "df_6 = df_6.T.reset_index().T.reset_index().drop(columns='index')\n",
    "df_7 = df_7.T.reset_index().T.reset_index().drop(columns='index')\n",
    "df_8 = df_8.T.reset_index().T.reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert the sentiment negative as -1 and positive as 1 into dataframe\n",
    "df_1['sentiment'] = -1\n",
    "df_2['sentiment'] = -1\n",
    "df_3['sentiment'] = -1\n",
    "df_4['sentiment'] = -1\n",
    "df_9['sentiment'] = -1\n",
    "\n",
    "df_5['sentiment'] = 1\n",
    "df_6['sentiment'] = 1\n",
    "df_7['sentiment'] = 1\n",
    "df_8['sentiment'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert the sentiment if there are have 1 hate speech or abusive then it concluded to negative (-1)\n",
    "# but if there are no hate speech or abusive then it concluded to positive (1)\n",
    "df_10['sentiment'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df_10.shape[0]):\n",
    "    if df_10.loc[i]['HS'] == 0 and df_10.loc[i]['Abusive'] == 0 and df_10.loc[i]['HS_Individual'] == 0 and df_10.loc[i]['HS_Group'] == 0 and df_10.loc[i]['HS_Religion'] == 0 and df_10.loc[i]['HS_Race'] == 0 and df_10.loc[i]['HS_Physical'] == 0 and df_10.loc[i]['HS_Gender'] == 0 and df_10.loc[i]['HS_Other'] == 0 and df_10.loc[i]['HS_Weak'] == 0 and df_10.loc[i]['HS_Moderate'] == 0 and df_10.loc[i]['HS_Strong'] == 0:\n",
    "        df_10['sentiment'][i] += \"1\"\n",
    "    else:\n",
    "        df_10['sentiment'][i] += \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makna_emoji(text):\n",
    "    text_split = text.split(' ')\n",
    "    text_join = '_'.join(text_split)\n",
    "    return text_join \n",
    "\n",
    "df_12['Makna Emoji'] = df_12['Makna Emoji'].apply(lambda i: makna_emoji(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10_new = df_10[['Tweet','sentiment']]\n",
    "df_11_new = df_11[['Text Tweet','Sentiment']]\n",
    "df_12_new = df_12[['Makna Emoji','Sentiment']]\n",
    "df_13_new = df_13[['Instagram Comment Text','Sentiment']]\n",
    "df_14_new = df_14[['Text Tweet','Sentiment']]\n",
    "df_15_new = df_15[['Text Tweet','Sentiment']]\n",
    "df_16_new = df_16[['Text Tweet','Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe 1 (Negative Words) (306, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>basi</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0  sentiment\n",
       "137  basi         -1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Dataframe 2 (Negative Words) (3829, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>dikasari</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  sentiment\n",
       "857  dikasari         -1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Dataframe 3 (Negative Words) (154, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bubarkan</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  sentiment\n",
       "27  bubarkan         -1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Dataframe 4 (Negative Words) (3523, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>mengoyak-oyak</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0  sentiment\n",
       "2061  mengoyak-oyak         -1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Dataframe 9 (Negative Words) (125, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABUSIVE</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>ngentot</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ABUSIVE  sentiment\n",
       "61  ngentot         -1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# displaying dataframe contains negative word\n",
    "print(\"Dataframe 1 (Negative Words)\", df_1.shape)\n",
    "display(df_1.sample())\n",
    "print(\" \")\n",
    "print(\"Dataframe 2 (Negative Words)\", df_2.shape)\n",
    "display(df_2.sample())\n",
    "print(\" \")\n",
    "print(\"Dataframe 3 (Negative Words)\", df_3.shape)\n",
    "display(df_3.sample())\n",
    "print(\" \")\n",
    "print(\"Dataframe 4 (Negative Words)\", df_4.shape)\n",
    "display(df_4.sample())\n",
    "print(\" \")\n",
    "print(\"Dataframe 9 (Negative Words)\", df_9.shape)\n",
    "display(df_9.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe 5 (Positive Words) (385, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>ridha</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  sentiment\n",
       "302  ridha          1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Dataframe 6 (Positive Words) (1678, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>nyaman</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  sentiment\n",
       "1307  nyaman          1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Dataframe 7 (Positive Words) (40, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bimbingan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  sentiment\n",
       "4  bimbingan          1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Dataframe 8 (Positive Words) (1293, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>secepatnya</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  sentiment\n",
       "1079  secepatnya          1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# displaying dataframe contains positive word\n",
    "print(\"Dataframe 5 (Positive Words)\", df_5.shape)\n",
    "display(df_5.sample())\n",
    "print(\" \")\n",
    "print(\"Dataframe 6 (Positive Words)\", df_6.shape)\n",
    "display(df_6.sample())\n",
    "print(\" \")\n",
    "print(\"Dataframe 7 (Positive Words)\", df_7.shape)\n",
    "display(df_7.sample())\n",
    "print(\" \")\n",
    "print(\"Dataframe 8 (Positive Words)\", df_8.shape)\n",
    "display(df_8.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe 10 (Tweet from User) (13169, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>RT USER USER USER USER Bener kamu ngga ada apa...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet sentiment\n",
       "11821  RT USER USER USER USER Bener kamu ngga ada apa...        -1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Dataframe 11 (Tweet from User) (300, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Sinyal kami paling kuat KATANYA. internetku di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Text Tweet Sentiment\n",
       "90  Sinyal kami paling kuat KATANYA. internetku di...  negative"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Dataframe 12 (Emoji) (165, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Makna Emoji</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Speak-No-Evil_Monkey</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Makna Emoji Sentiment\n",
       "26  Speak-No-Evil_Monkey  negative"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# displaying dataframe from tweet and emoji\n",
    "print(\"Dataframe 10 (Tweet from User)\", df_10_new.shape)\n",
    "display(df_10_new.sample())\n",
    "print(\" \")\n",
    "print(\"Dataframe 11 (Tweet from User)\", df_11_new.shape)\n",
    "display(df_11_new.sample())\n",
    "print(\" \")\n",
    "print(\"Dataframe 12 (Emoji)\", df_12_new.shape)\n",
    "display(df_12_new.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column 0 into Text\n",
    "df_1 = df_1.rename(columns={0: 'Text'})\n",
    "df_2 = df_2.rename(columns={0: 'Text'})\n",
    "df_3 = df_3.rename(columns={0: 'Text'})\n",
    "df_4 = df_4.rename(columns={0: 'Text'})\n",
    "df_9 = df_9.rename(columns={'ABUSIVE': 'Text'})\n",
    "\n",
    "df_5 = df_5.rename(columns={0: 'Text'})\n",
    "df_6 = df_6.rename(columns={0: 'Text'})\n",
    "df_7 = df_7.rename(columns={0: 'Text'})\n",
    "df_8 = df_8.rename(columns={0: 'Text'})\n",
    "\n",
    "df_9 = df_9.rename(columns={'ABUSIVE': 'Text'})\n",
    "df_10_new = df_10_new.rename(columns={'Tweet': 'Text'})\n",
    "df_11_new = df_11_new.rename(columns={'Text Tweet': 'Text', 'Sentiment' : 'sentiment'})\n",
    "df_12_new = df_12_new.rename(columns={'Makna Emoji': 'Text', 'Sentiment' : 'sentiment'})\n",
    "df_13_new = df_13_new.rename(columns={'Instagram Comment Text': 'Text', 'Sentiment' : 'sentiment'})\n",
    "df_14_new = df_14_new.rename(columns={'Text Tweet': 'Text', 'Sentiment' : 'sentiment'})\n",
    "df_15_new = df_15_new.rename(columns={'Text Tweet': 'Text', 'Sentiment' : 'sentiment'})\n",
    "df_16_new = df_16_new.rename(columns={'Text Tweet': 'Text', 'Sentiment' : 'sentiment'})\n",
    "\n",
    "df_11_new = df_11_new.replace({'positive': '1', 'negative' : '-1'})\n",
    "df_12_new = df_12_new.replace({'positive': '1', 'negative' : '-1'})\n",
    "df_13_new = df_13_new.replace({'positive': '1', 'negative' : '-1'})\n",
    "df_14_new = df_14_new.replace({'positive': '1', 'negative' : '-1'})\n",
    "df_15_new = df_15_new.replace({'positive': '1', 'negative' : '-1'})\n",
    "df_16_new = df_16_new.replace({'positive': '1', 'negative' : '-1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inkonsisten</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>porno</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>teroris</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sesat</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tuntut</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26862</th>\n",
       "      <td>Kali saja bpk @aniesbaswedan @sandiuno lihat, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26863</th>\n",
       "      <td>Kita harus dapat merangkul semua orang tanpa b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26864</th>\n",
       "      <td>Ini jagoanku dibidang digital &lt;Smiling Face Wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26865</th>\n",
       "      <td>#PesanBijak #OkeOce #GubernurGu3 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26866</th>\n",
       "      <td>Sandiaga: Bangun Rumah DP 0% Lebih Simpel Diba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26867 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text sentiment\n",
       "0                                            inkonsisten        -1\n",
       "1                                                  porno        -1\n",
       "2                                                teroris        -1\n",
       "3                                                  sesat        -1\n",
       "4                                                 tuntut        -1\n",
       "...                                                  ...       ...\n",
       "26862  Kali saja bpk @aniesbaswedan @sandiuno lihat, ...         1\n",
       "26863  Kita harus dapat merangkul semua orang tanpa b...         1\n",
       "26864  Ini jagoanku dibidang digital <Smiling Face Wi...         1\n",
       "26865               #PesanBijak #OkeOce #GubernurGu3 ...         1\n",
       "26866  Sandiaga: Bangun Rumah DP 0% Lebih Simpel Diba...         1\n",
       "\n",
       "[26867 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the dataframes is ready to concat\n",
    "df = pd.concat([df_1, df_2, df_3, df_4, df_5, df_6, df_7, df_8, df_9, df_10_new, df_11_new, df_12_new, df_13_new, df_14_new, df_15_new, df_16_new], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['sentiment'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>0.612052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.387948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0         count\n",
       "sentiment          \n",
       "-1         0.612052\n",
       " 1         0.387948"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(index=df['sentiment'], columns='count', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('Sentiment_Analysis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text         0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handling missing value, there is no missing value on this dataset\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before drop duplicates data : 26867\n",
      "unique data : 20298\n"
     ]
    }
   ],
   "source": [
    "# handling duplicates data\n",
    "print('before drop duplicates data :', len(df))\n",
    "print('unique data :', df['Text'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after drop duplicates data : 20298\n",
      "unique data : 20298\n"
     ]
    }
   ],
   "source": [
    "df.drop_duplicates(['Text'], inplace=True)\n",
    "print('after drop duplicates data :', len(df))\n",
    "print('unique data :', df['Text'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inkonsisten</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>porno</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>teroris</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sesat</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tuntut</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20293</th>\n",
       "      <td>Kali saja bpk @aniesbaswedan @sandiuno lihat, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20294</th>\n",
       "      <td>Kita harus dapat merangkul semua orang tanpa b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20295</th>\n",
       "      <td>Ini jagoanku dibidang digital &lt;Smiling Face Wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20296</th>\n",
       "      <td>#PesanBijak #OkeOce #GubernurGu3 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20297</th>\n",
       "      <td>Sandiaga: Bangun Rumah DP 0% Lebih Simpel Diba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20298 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  sentiment\n",
       "0                                            inkonsisten         -1\n",
       "1                                                  porno         -1\n",
       "2                                                teroris         -1\n",
       "3                                                  sesat         -1\n",
       "4                                                 tuntut         -1\n",
       "...                                                  ...        ...\n",
       "20293  Kali saja bpk @aniesbaswedan @sandiuno lihat, ...          1\n",
       "20294  Kita harus dapat merangkul semua orang tanpa b...          1\n",
       "20295  Ini jagoanku dibidang digital <Smiling Face Wi...          1\n",
       "20296               #PesanBijak #OkeOce #GubernurGu3 ...          1\n",
       "20297  Sandiaga: Bangun Rumah DP 0% Lebih Simpel Diba...          1\n",
       "\n",
       "[20298 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the dataframe is ready to use\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing emoji dataframe to dictionary\n",
    "df_12_emoji = df_12[['Emoji', 'Makna Emoji']]\n",
    "df_12_emoji = df_12_emoji.set_index('Emoji')\n",
    "df_12_emoji_new = df_12_emoji.to_dict()\n",
    "df_12_emoji_new = df_12_emoji_new['Makna Emoji']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing slang words dataframe to dictionary\n",
    "df_13 = pd.read_csv('new_kamusalay.csv', encoding='latin-1')\n",
    "df_13 = df_13.T.reset_index().T.reset_index().drop(columns='index')\n",
    "df_13 = df_13.set_index(0)\n",
    "df_13_new = df_13.to_dict()\n",
    "df_13_new = df_13_new[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"RT USER: Yang beginian Kecoak dan Belatung pasti gak paham. Yang mereka tahu hanya bagaimana mengambil kebijakan seenak jidatnya sendiri\\\\xe2\\\\x80\\\\xa6'\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text'][12001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dongkrak bonus dr dealer ga enak amat ya kek ngerakit\"...\\\\n.\\\\n.\\\\n.\\\\n.\\\\nPengen beli dongkrak (buaya)\\''"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text'][13067]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ratusan Massa Ormas Islam Geruduk LBH Jakarta: Ganyang PKI! URL URL'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text'][13197]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since I found text like this above, which contains the text 'USER', 'RT or retweet', 'http', 'url', '\\n', and unicode UTF-8 character in literal and also I can't convert this utf-8 character emoji, therefore I handle it and decide to drop the words containing like xa, xf, x, etc without numbers and '\\' refer to source https://www.utf8-chartable.de/unicode-utf8-table.pl?start=128512&number=1024&names=2&utf8=string-literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "exception = ['user', 'rt', 'http', 'url', 'n', 'x', 'xa', 'xb', 'xc', 'xd', 'xe', 'xf', 'xaa', 'xab', 'xac', 'xad', 'xae', 'xaf', 'xba', 'xbb', 'xbc', 'xbd', 'xbe', 'xbf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few steps for text processing :\n",
    "1. Lowering all words from Text\n",
    "2. Tokenize the sentence from Text\n",
    "3. Removing all numbers from Text\n",
    "4. Removing punctuation from Text\n",
    "5. Removing like user, retweet, http, etc from Text\n",
    "6. Removing Indonesian stopwords from Text\n",
    "7. Converting Indonesian slang words from Text\n",
    "8. Converting emoji into Meaning of the Emoji\n",
    "9. Using Sastrawi for stemming process\n",
    "10. Tokenize the stemmed text\n",
    "11. Removing Indonesian stopwords  after stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## =================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Lowering all words from Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowering all words from text\n",
    "df['text_lower'] = [i.lower() for i in df['Text']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15149</th>\n",
       "      <td>USER USER USER Admin USER ini emang kebangetan...</td>\n",
       "      <td>-1</td>\n",
       "      <td>user user user admin user ini emang kebangetan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  sentiment  \\\n",
       "15149  USER USER USER Admin USER ini emang kebangetan...         -1   \n",
       "\n",
       "                                              text_lower  \n",
       "15149  user user user admin user ini emang kebangetan...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tokenize the sentence from Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the sentence\n",
    "df['text_token'] = [word_tokenize(i) for i in df['text_lower']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19698</th>\n",
       "      <td>Bukan kah #AHY sdh menunjukkan Jiwa besar dala...</td>\n",
       "      <td>1</td>\n",
       "      <td>bukan kah #ahy sdh menunjukkan jiwa besar dala...</td>\n",
       "      <td>[bukan, kah, #, ahy, sdh, menunjukkan, jiwa, b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  sentiment  \\\n",
       "19698  Bukan kah #AHY sdh menunjukkan Jiwa besar dala...          1   \n",
       "\n",
       "                                              text_lower  \\\n",
       "19698  bukan kah #ahy sdh menunjukkan jiwa besar dala...   \n",
       "\n",
       "                                              text_token  \n",
       "19698  [bukan, kah, #, ahy, sdh, menunjukkan, jiwa, b...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Removing all numbers from Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing numeric\n",
    "def removedigit(text):\n",
    "    nondigit = ' '.join(i for i in text if not i.isdigit())\n",
    "    return word_tokenize(nondigit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_without_number'] = df['text_token'].apply(lambda i: removedigit(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_token</th>\n",
       "      <th>text_without_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18813</th>\n",
       "      <td>Terima kasih pak.... Sudah mau membantu kami u...</td>\n",
       "      <td>1</td>\n",
       "      <td>terima kasih pak.... sudah mau membantu kami u...</td>\n",
       "      <td>[terima, kasih, pak, ...., sudah, mau, membant...</td>\n",
       "      <td>[terima, kasih, pak, ...., sudah, mau, membant...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  sentiment  \\\n",
       "18813  Terima kasih pak.... Sudah mau membantu kami u...          1   \n",
       "\n",
       "                                              text_lower  \\\n",
       "18813  terima kasih pak.... sudah mau membantu kami u...   \n",
       "\n",
       "                                              text_token  \\\n",
       "18813  [terima, kasih, pak, ...., sudah, mau, membant...   \n",
       "\n",
       "                                     text_without_number  \n",
       "18813  [terima, kasih, pak, ...., sudah, mau, membant...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Removing punctuation from Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing punctuation\n",
    "def remove_punctuation(text):\n",
    "    return word_tokenize(' '.join(i for i in text if i not in punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_no_punctuation'] = df['text_without_number'].apply(lambda i: remove_punctuation(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_token</th>\n",
       "      <th>text_without_number</th>\n",
       "      <th>text_no_punctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19331</th>\n",
       "      <td>Papa mama aku juga ikut nonton , mereka termas...</td>\n",
       "      <td>1</td>\n",
       "      <td>papa mama aku juga ikut nonton , mereka termas...</td>\n",
       "      <td>[papa, mama, aku, juga, ikut, nonton, ,, merek...</td>\n",
       "      <td>[papa, mama, aku, juga, ikut, nonton, ,, merek...</td>\n",
       "      <td>[papa, mama, aku, juga, ikut, nonton, mereka, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  sentiment  \\\n",
       "19331  Papa mama aku juga ikut nonton , mereka termas...          1   \n",
       "\n",
       "                                              text_lower  \\\n",
       "19331  papa mama aku juga ikut nonton , mereka termas...   \n",
       "\n",
       "                                              text_token  \\\n",
       "19331  [papa, mama, aku, juga, ikut, nonton, ,, merek...   \n",
       "\n",
       "                                     text_without_number  \\\n",
       "19331  [papa, mama, aku, juga, ikut, nonton, ,, merek...   \n",
       "\n",
       "                                     text_no_punctuation  \n",
       "19331  [papa, mama, aku, juga, ikut, nonton, mereka, ...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Removing like user, retweet, http, etc from Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing like user, retweet, http, url, etc...\n",
    "def remove_exception(text):\n",
    "    return word_tokenize(' '.join(i for i in text if (i not in exception) and (i.isalnum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_exception'] = df['text_no_punctuation'].apply(lambda i: remove_exception(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_token</th>\n",
       "      <th>text_without_number</th>\n",
       "      <th>text_no_punctuation</th>\n",
       "      <th>text_exception</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>pupus</td>\n",
       "      <td>-1</td>\n",
       "      <td>pupus</td>\n",
       "      <td>[pupus]</td>\n",
       "      <td>[pupus]</td>\n",
       "      <td>[pupus]</td>\n",
       "      <td>[pupus]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Text  sentiment text_lower text_token text_without_number  \\\n",
       "250  pupus         -1      pupus    [pupus]             [pupus]   \n",
       "\n",
       "    text_no_punctuation text_exception  \n",
       "250             [pupus]        [pupus]  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Removing Indonesian stopwords from Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stopwords\n",
    "def remove_stopwords(text):\n",
    "    return word_tokenize(' '.join(i for i in text if i not in stopwords.words('indonesian')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_no_stopwords'] = df['text_exception'].apply(lambda i: remove_stopwords(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_token</th>\n",
       "      <th>text_without_number</th>\n",
       "      <th>text_no_punctuation</th>\n",
       "      <th>text_exception</th>\n",
       "      <th>text_no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6635</th>\n",
       "      <td>Pada momen kegiatan budaya ini, telah direncan...</td>\n",
       "      <td>1</td>\n",
       "      <td>pada momen kegiatan budaya ini, telah direncan...</td>\n",
       "      <td>[pada, momen, kegiatan, budaya, ini, ,, telah,...</td>\n",
       "      <td>[pada, momen, kegiatan, budaya, ini, ,, telah,...</td>\n",
       "      <td>[pada, momen, kegiatan, budaya, ini, telah, di...</td>\n",
       "      <td>[pada, momen, kegiatan, budaya, ini, telah, di...</td>\n",
       "      <td>[momen, kegiatan, budaya, direncanakan, ribuan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  sentiment  \\\n",
       "6635  Pada momen kegiatan budaya ini, telah direncan...          1   \n",
       "\n",
       "                                             text_lower  \\\n",
       "6635  pada momen kegiatan budaya ini, telah direncan...   \n",
       "\n",
       "                                             text_token  \\\n",
       "6635  [pada, momen, kegiatan, budaya, ini, ,, telah,...   \n",
       "\n",
       "                                    text_without_number  \\\n",
       "6635  [pada, momen, kegiatan, budaya, ini, ,, telah,...   \n",
       "\n",
       "                                    text_no_punctuation  \\\n",
       "6635  [pada, momen, kegiatan, budaya, ini, telah, di...   \n",
       "\n",
       "                                         text_exception  \\\n",
       "6635  [pada, momen, kegiatan, budaya, ini, telah, di...   \n",
       "\n",
       "                                      text_no_stopwords  \n",
       "6635  [momen, kegiatan, budaya, direncanakan, ribuan...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Converting Indonesian slang words from Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting Indonesian slang words\n",
    "def converter_slangwords(text):\n",
    "    for i in text:\n",
    "        if i in list(df_13_new.keys()):\n",
    "            text[text.index(i)] = df_13_new[i]\n",
    "        else:\n",
    "            pass\n",
    "    text_converted = word_tokenize(\" \".join(text))\n",
    "    return text_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['convert_slangwords'] = df['text_no_stopwords'].apply(lambda i: converter_slangwords(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_token</th>\n",
       "      <th>text_without_number</th>\n",
       "      <th>text_no_punctuation</th>\n",
       "      <th>text_exception</th>\n",
       "      <th>text_no_stopwords</th>\n",
       "      <th>convert_slangwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7001</th>\n",
       "      <td>USER Jan kenceng2 ketawanya kaya kunti aja'</td>\n",
       "      <td>1</td>\n",
       "      <td>user jan kenceng2 ketawanya kaya kunti aja'</td>\n",
       "      <td>[user, jan, kenceng2, ketawanya, kaya, kunti, ...</td>\n",
       "      <td>[user, jan, kenceng2, ketawanya, kaya, kunti, ...</td>\n",
       "      <td>[user, jan, kenceng2, ketawanya, kaya, kunti, ...</td>\n",
       "      <td>[jan, kenceng2, ketawanya, kaya, kunti, aja]</td>\n",
       "      <td>[jangan, cepat cepat, ketawanya, kayak, kunti,...</td>\n",
       "      <td>[jangan, cepat, cepat, ketawanya, kayak, kunti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Text  sentiment  \\\n",
       "7001  USER Jan kenceng2 ketawanya kaya kunti aja'          1   \n",
       "\n",
       "                                       text_lower  \\\n",
       "7001  user jan kenceng2 ketawanya kaya kunti aja'   \n",
       "\n",
       "                                             text_token  \\\n",
       "7001  [user, jan, kenceng2, ketawanya, kaya, kunti, ...   \n",
       "\n",
       "                                    text_without_number  \\\n",
       "7001  [user, jan, kenceng2, ketawanya, kaya, kunti, ...   \n",
       "\n",
       "                                    text_no_punctuation  \\\n",
       "7001  [user, jan, kenceng2, ketawanya, kaya, kunti, ...   \n",
       "\n",
       "                                    text_exception  \\\n",
       "7001  [jan, kenceng2, ketawanya, kaya, kunti, aja]   \n",
       "\n",
       "                                      text_no_stopwords  \\\n",
       "7001  [jangan, cepat cepat, ketawanya, kayak, kunti,...   \n",
       "\n",
       "                                     convert_slangwords  \n",
       "7001  [jangan, cepat, cepat, ketawanya, kayak, kunti...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Converting emoji into Meaning of the Emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting Emoji into Meaning of the Emoji\n",
    "def converter_emojimeaning(text):\n",
    "    for i in text:\n",
    "        if i in list(df_12_emoji_new.keys()):\n",
    "            text[text.index(i)] = df_12_emoji_new[i]\n",
    "        else:\n",
    "            pass\n",
    "    text_converted_emoji = word_tokenize(\" \".join(text))\n",
    "    return text_converted_emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['convert_emojimeaning'] = df['convert_slangwords'].apply(lambda i: converter_emojimeaning(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_token</th>\n",
       "      <th>text_without_number</th>\n",
       "      <th>text_no_punctuation</th>\n",
       "      <th>text_exception</th>\n",
       "      <th>text_no_stopwords</th>\n",
       "      <th>convert_slangwords</th>\n",
       "      <th>convert_emojimeaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13060</th>\n",
       "      <td>USER Telusuri cepat pertemuan Hatta Ali dengan...</td>\n",
       "      <td>-1</td>\n",
       "      <td>user telusuri cepat pertemuan hatta ali dengan...</td>\n",
       "      <td>[user, telusuri, cepat, pertemuan, hatta, ali,...</td>\n",
       "      <td>[user, telusuri, cepat, pertemuan, hatta, ali,...</td>\n",
       "      <td>[user, telusuri, cepat, pertemuan, hatta, ali,...</td>\n",
       "      <td>[telusuri, cepat, pertemuan, hatta, ali, denga...</td>\n",
       "      <td>[telusuri, cepat, pertemuan, hatta, ali, setya...</td>\n",
       "      <td>[telusuri, cepat, pertemuan, hatta, ali, setya...</td>\n",
       "      <td>[telusuri, cepat, pertemuan, hatta, ali, setya...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  sentiment  \\\n",
       "13060  USER Telusuri cepat pertemuan Hatta Ali dengan...         -1   \n",
       "\n",
       "                                              text_lower  \\\n",
       "13060  user telusuri cepat pertemuan hatta ali dengan...   \n",
       "\n",
       "                                              text_token  \\\n",
       "13060  [user, telusuri, cepat, pertemuan, hatta, ali,...   \n",
       "\n",
       "                                     text_without_number  \\\n",
       "13060  [user, telusuri, cepat, pertemuan, hatta, ali,...   \n",
       "\n",
       "                                     text_no_punctuation  \\\n",
       "13060  [user, telusuri, cepat, pertemuan, hatta, ali,...   \n",
       "\n",
       "                                          text_exception  \\\n",
       "13060  [telusuri, cepat, pertemuan, hatta, ali, denga...   \n",
       "\n",
       "                                       text_no_stopwords  \\\n",
       "13060  [telusuri, cepat, pertemuan, hatta, ali, setya...   \n",
       "\n",
       "                                      convert_slangwords  \\\n",
       "13060  [telusuri, cepat, pertemuan, hatta, ali, setya...   \n",
       "\n",
       "                                    convert_emojimeaning  \n",
       "13060  [telusuri, cepat, pertemuan, hatta, ali, setya...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpacking from word tokenize into a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpacking(text):\n",
    "    return (' '.join(i for i in text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['unpacking_sentence'] = df['convert_emojimeaning'].apply(lambda i: unpacking(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_token</th>\n",
       "      <th>text_without_number</th>\n",
       "      <th>text_no_punctuation</th>\n",
       "      <th>text_exception</th>\n",
       "      <th>text_no_stopwords</th>\n",
       "      <th>convert_slangwords</th>\n",
       "      <th>convert_emojimeaning</th>\n",
       "      <th>unpacking_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6044</th>\n",
       "      <td>Aku heran deh kenapa yaa kamu gak capek lari-l...</td>\n",
       "      <td>1</td>\n",
       "      <td>aku heran deh kenapa yaa kamu gak capek lari-l...</td>\n",
       "      <td>[aku, heran, deh, kenapa, yaa, kamu, gak, cape...</td>\n",
       "      <td>[aku, heran, deh, kenapa, yaa, kamu, gak, cape...</td>\n",
       "      <td>[aku, heran, deh, kenapa, yaa, kamu, gak, cape...</td>\n",
       "      <td>[aku, heran, deh, kenapa, yaa, kamu, gak, cape...</td>\n",
       "      <td>[heran, deh, ya, tidak, cape, pikiranku]</td>\n",
       "      <td>[heran, deh, ya, tidak, cape, pikiranku]</td>\n",
       "      <td>[heran, deh, ya, tidak, cape, pikiranku]</td>\n",
       "      <td>heran deh ya tidak cape pikiranku</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  sentiment  \\\n",
       "6044  Aku heran deh kenapa yaa kamu gak capek lari-l...          1   \n",
       "\n",
       "                                             text_lower  \\\n",
       "6044  aku heran deh kenapa yaa kamu gak capek lari-l...   \n",
       "\n",
       "                                             text_token  \\\n",
       "6044  [aku, heran, deh, kenapa, yaa, kamu, gak, cape...   \n",
       "\n",
       "                                    text_without_number  \\\n",
       "6044  [aku, heran, deh, kenapa, yaa, kamu, gak, cape...   \n",
       "\n",
       "                                    text_no_punctuation  \\\n",
       "6044  [aku, heran, deh, kenapa, yaa, kamu, gak, cape...   \n",
       "\n",
       "                                         text_exception  \\\n",
       "6044  [aku, heran, deh, kenapa, yaa, kamu, gak, cape...   \n",
       "\n",
       "                             text_no_stopwords  \\\n",
       "6044  [heran, deh, ya, tidak, cape, pikiranku]   \n",
       "\n",
       "                            convert_slangwords  \\\n",
       "6044  [heran, deh, ya, tidak, cape, pikiranku]   \n",
       "\n",
       "                          convert_emojimeaning  \\\n",
       "6044  [heran, deh, ya, tidak, cape, pikiranku]   \n",
       "\n",
       "                     unpacking_sentence  \n",
       "6044  heran deh ya tidak cape pikiranku  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'begitu ajakan belum diam ya divisi kerja bikin set'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[10195]['unpacking_sentence']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Using Sastrawi for stemming process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(text):\n",
    "    stem_text = stemmer.stem(text)\n",
    "    return stem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stemmed'] = df['unpacking_sentence'].apply(lambda i: stemming(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_token</th>\n",
       "      <th>text_without_number</th>\n",
       "      <th>text_no_punctuation</th>\n",
       "      <th>text_exception</th>\n",
       "      <th>text_no_stopwords</th>\n",
       "      <th>convert_slangwords</th>\n",
       "      <th>convert_emojimeaning</th>\n",
       "      <th>unpacking_sentence</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>gelepar</td>\n",
       "      <td>-1</td>\n",
       "      <td>gelepar</td>\n",
       "      <td>[gelepar]</td>\n",
       "      <td>[gelepar]</td>\n",
       "      <td>[gelepar]</td>\n",
       "      <td>[gelepar]</td>\n",
       "      <td>[gelepar]</td>\n",
       "      <td>[gelepar]</td>\n",
       "      <td>[gelepar]</td>\n",
       "      <td>gelepar</td>\n",
       "      <td>gelepar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Text  sentiment text_lower text_token text_without_number  \\\n",
       "1193  gelepar         -1    gelepar  [gelepar]           [gelepar]   \n",
       "\n",
       "     text_no_punctuation text_exception text_no_stopwords convert_slangwords  \\\n",
       "1193           [gelepar]      [gelepar]         [gelepar]          [gelepar]   \n",
       "\n",
       "     convert_emojimeaning unpacking_sentence  stemmed  \n",
       "1193            [gelepar]            gelepar  gelepar  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Tokenize the stemmed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the stemmed text\n",
    "df['text_token_stemmed'] = [word_tokenize(i) for i in df['stemmed']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_token</th>\n",
       "      <th>text_without_number</th>\n",
       "      <th>text_no_punctuation</th>\n",
       "      <th>text_exception</th>\n",
       "      <th>text_no_stopwords</th>\n",
       "      <th>convert_slangwords</th>\n",
       "      <th>convert_emojimeaning</th>\n",
       "      <th>unpacking_sentence</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>text_token_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11641</th>\n",
       "      <td>USER Padahal shua cuma saudara jauhnya kunti l...</td>\n",
       "      <td>1</td>\n",
       "      <td>user padahal shua cuma saudara jauhnya kunti l...</td>\n",
       "      <td>[user, padahal, shua, cuma, saudara, jauhnya, ...</td>\n",
       "      <td>[user, padahal, shua, cuma, saudara, jauhnya, ...</td>\n",
       "      <td>[user, padahal, shua, cuma, saudara, jauhnya, ...</td>\n",
       "      <td>[padahal, shua, cuma, saudara, jauhnya, kunti,...</td>\n",
       "      <td>[shua, saudara, jauhnya, kunti, lah, oppa]</td>\n",
       "      <td>[shua, saudara, jauhnya, kunti, lah, oppa]</td>\n",
       "      <td>[shua, saudara, jauhnya, kunti, lah, oppa]</td>\n",
       "      <td>shua saudara jauhnya kunti lah oppa</td>\n",
       "      <td>shua saudara jauh kunti lah oppa</td>\n",
       "      <td>[shua, saudara, jauh, kunti, lah, oppa]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  sentiment  \\\n",
       "11641  USER Padahal shua cuma saudara jauhnya kunti l...          1   \n",
       "\n",
       "                                              text_lower  \\\n",
       "11641  user padahal shua cuma saudara jauhnya kunti l...   \n",
       "\n",
       "                                              text_token  \\\n",
       "11641  [user, padahal, shua, cuma, saudara, jauhnya, ...   \n",
       "\n",
       "                                     text_without_number  \\\n",
       "11641  [user, padahal, shua, cuma, saudara, jauhnya, ...   \n",
       "\n",
       "                                     text_no_punctuation  \\\n",
       "11641  [user, padahal, shua, cuma, saudara, jauhnya, ...   \n",
       "\n",
       "                                          text_exception  \\\n",
       "11641  [padahal, shua, cuma, saudara, jauhnya, kunti,...   \n",
       "\n",
       "                                text_no_stopwords  \\\n",
       "11641  [shua, saudara, jauhnya, kunti, lah, oppa]   \n",
       "\n",
       "                               convert_slangwords  \\\n",
       "11641  [shua, saudara, jauhnya, kunti, lah, oppa]   \n",
       "\n",
       "                             convert_emojimeaning  \\\n",
       "11641  [shua, saudara, jauhnya, kunti, lah, oppa]   \n",
       "\n",
       "                        unpacking_sentence                           stemmed  \\\n",
       "11641  shua saudara jauhnya kunti lah oppa  shua saudara jauh kunti lah oppa   \n",
       "\n",
       "                            text_token_stemmed  \n",
       "11641  [shua, saudara, jauh, kunti, lah, oppa]  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Removing Indonesian stopwords from Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stopwords\n",
    "def remove_stopwords(text):\n",
    "    return word_tokenize(' '.join(i for i in text if i not in stopwords.words('indonesian')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_no_stopwords_stemmed'] = df['text_token_stemmed'].apply(lambda i: remove_stopwords(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_token</th>\n",
       "      <th>text_without_number</th>\n",
       "      <th>text_no_punctuation</th>\n",
       "      <th>text_exception</th>\n",
       "      <th>text_no_stopwords</th>\n",
       "      <th>convert_slangwords</th>\n",
       "      <th>convert_emojimeaning</th>\n",
       "      <th>unpacking_sentence</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>text_token_stemmed</th>\n",
       "      <th>text_no_stopwords_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18232</th>\n",
       "      <td>Upload file yang besar juga sangat mudah denga...</td>\n",
       "      <td>1</td>\n",
       "      <td>upload file yang besar juga sangat mudah denga...</td>\n",
       "      <td>[upload, file, yang, besar, juga, sangat, muda...</td>\n",
       "      <td>[upload, file, yang, besar, juga, sangat, muda...</td>\n",
       "      <td>[upload, file, yang, besar, juga, sangat, muda...</td>\n",
       "      <td>[upload, file, yang, besar, juga, sangat, muda...</td>\n",
       "      <td>[unggah, file, mudah, jaringan, internetnya, c...</td>\n",
       "      <td>[unggah, file, mudah, jaringan, internetnya, c...</td>\n",
       "      <td>[unggah, file, mudah, jaringan, internetnya, c...</td>\n",
       "      <td>unggah file mudah jaringan internetnya cepat a...</td>\n",
       "      <td>unggah file mudah jaring internetnya cepat alh...</td>\n",
       "      <td>[unggah, file, mudah, jaring, internetnya, cep...</td>\n",
       "      <td>[unggah, file, mudah, jaring, internetnya, cep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  sentiment  \\\n",
       "18232  Upload file yang besar juga sangat mudah denga...          1   \n",
       "\n",
       "                                              text_lower  \\\n",
       "18232  upload file yang besar juga sangat mudah denga...   \n",
       "\n",
       "                                              text_token  \\\n",
       "18232  [upload, file, yang, besar, juga, sangat, muda...   \n",
       "\n",
       "                                     text_without_number  \\\n",
       "18232  [upload, file, yang, besar, juga, sangat, muda...   \n",
       "\n",
       "                                     text_no_punctuation  \\\n",
       "18232  [upload, file, yang, besar, juga, sangat, muda...   \n",
       "\n",
       "                                          text_exception  \\\n",
       "18232  [upload, file, yang, besar, juga, sangat, muda...   \n",
       "\n",
       "                                       text_no_stopwords  \\\n",
       "18232  [unggah, file, mudah, jaringan, internetnya, c...   \n",
       "\n",
       "                                      convert_slangwords  \\\n",
       "18232  [unggah, file, mudah, jaringan, internetnya, c...   \n",
       "\n",
       "                                    convert_emojimeaning  \\\n",
       "18232  [unggah, file, mudah, jaringan, internetnya, c...   \n",
       "\n",
       "                                      unpacking_sentence  \\\n",
       "18232  unggah file mudah jaringan internetnya cepat a...   \n",
       "\n",
       "                                                 stemmed  \\\n",
       "18232  unggah file mudah jaring internetnya cepat alh...   \n",
       "\n",
       "                                      text_token_stemmed  \\\n",
       "18232  [unggah, file, mudah, jaring, internetnya, cep...   \n",
       "\n",
       "                               text_no_stopwords_stemmed  \n",
       "18232  [unggah, file, mudah, jaring, internetnya, cep...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpacking from word tokenize into a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpacking(text):\n",
    "    return (' '.join(i for i in text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['final'] = df['text_no_stopwords_stemmed'].apply(lambda i: unpacking(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_token</th>\n",
       "      <th>text_without_number</th>\n",
       "      <th>text_no_punctuation</th>\n",
       "      <th>text_exception</th>\n",
       "      <th>text_no_stopwords</th>\n",
       "      <th>convert_slangwords</th>\n",
       "      <th>convert_emojimeaning</th>\n",
       "      <th>unpacking_sentence</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>text_token_stemmed</th>\n",
       "      <th>text_no_stopwords_stemmed</th>\n",
       "      <th>final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15784</th>\n",
       "      <td>USER Bajingan. Inter itu tim top dan hebat. La...</td>\n",
       "      <td>-1</td>\n",
       "      <td>user bajingan. inter itu tim top dan hebat. la...</td>\n",
       "      <td>[user, bajingan, ., inter, itu, tim, top, dan,...</td>\n",
       "      <td>[user, bajingan, ., inter, itu, tim, top, dan,...</td>\n",
       "      <td>[user, bajingan, inter, itu, tim, top, dan, he...</td>\n",
       "      <td>[bajingan, inter, itu, tim, top, dan, hebat, l...</td>\n",
       "      <td>[bajingan, inter, tim, top, hebat, lazio, yang...</td>\n",
       "      <td>[bajingan, inter, tim, top, hebat, lazio, yang...</td>\n",
       "      <td>[bajingan, inter, tim, top, hebat, lazio, yang...</td>\n",
       "      <td>bajingan inter tim top hebat lazio yang sampah</td>\n",
       "      <td>bajing inter tim top hebat lazio yang sampah</td>\n",
       "      <td>[bajing, inter, tim, top, hebat, lazio, yang, ...</td>\n",
       "      <td>[bajing, inter, tim, top, hebat, lazio, sampah]</td>\n",
       "      <td>bajing inter tim top hebat lazio sampah</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  sentiment  \\\n",
       "15784  USER Bajingan. Inter itu tim top dan hebat. La...         -1   \n",
       "\n",
       "                                              text_lower  \\\n",
       "15784  user bajingan. inter itu tim top dan hebat. la...   \n",
       "\n",
       "                                              text_token  \\\n",
       "15784  [user, bajingan, ., inter, itu, tim, top, dan,...   \n",
       "\n",
       "                                     text_without_number  \\\n",
       "15784  [user, bajingan, ., inter, itu, tim, top, dan,...   \n",
       "\n",
       "                                     text_no_punctuation  \\\n",
       "15784  [user, bajingan, inter, itu, tim, top, dan, he...   \n",
       "\n",
       "                                          text_exception  \\\n",
       "15784  [bajingan, inter, itu, tim, top, dan, hebat, l...   \n",
       "\n",
       "                                       text_no_stopwords  \\\n",
       "15784  [bajingan, inter, tim, top, hebat, lazio, yang...   \n",
       "\n",
       "                                      convert_slangwords  \\\n",
       "15784  [bajingan, inter, tim, top, hebat, lazio, yang...   \n",
       "\n",
       "                                    convert_emojimeaning  \\\n",
       "15784  [bajingan, inter, tim, top, hebat, lazio, yang...   \n",
       "\n",
       "                                   unpacking_sentence  \\\n",
       "15784  bajingan inter tim top hebat lazio yang sampah   \n",
       "\n",
       "                                            stemmed  \\\n",
       "15784  bajing inter tim top hebat lazio yang sampah   \n",
       "\n",
       "                                      text_token_stemmed  \\\n",
       "15784  [bajing, inter, tim, top, hebat, lazio, yang, ...   \n",
       "\n",
       "                             text_no_stopwords_stemmed  \\\n",
       "15784  [bajing, inter, tim, top, hebat, lazio, sampah]   \n",
       "\n",
       "                                         final  \n",
       "15784  bajing inter tim top hebat lazio sampah  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## =================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All steps have been done, we move to next Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('sentiment_analysis_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
